{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fer_tf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasirHabib/Deep-Learning-Convolutional-Neural-Networks-in-Python/blob/master/fer_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaYbuRyUoUv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H7jeXhaoxC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgswqMf77XWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_filter(shape):\n",
        "  w = np.random.randn(*shape) * np.sqrt(2.0 / np.prod(shape[:-1]))\n",
        "  return w.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ccz3iCOsd-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class convpool():\n",
        "  def __init__(self, num_feature_maps, num_color_channels, filter_width, filter_height, poolsz=(2, 2)):\n",
        "    self.poolsz = poolsz\n",
        "    sz = (filter_width, filter_height, num_color_channels, num_feature_maps)\n",
        "    W = init_filter(sz)\n",
        "    b = np.zeros(num_feature_maps, dtype=np.float32)\n",
        "    \n",
        "    self.W = tf.Variable(W)\n",
        "    self.b = tf.Variable(b)\n",
        "    \n",
        "    self.params = [self.W, self.b]\n",
        "    \n",
        "  def convpool_forward(self, X):\n",
        "    conv_out = tf.nn.conv2d(X, self.W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "    conv_out = tf.nn.bias_add(conv_out, self.b)\n",
        "    pool_out = tf.nn.max_pool(conv_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "    return tf.nn.relu(pool_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp7mb6ycD5Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HiddenLayer():\n",
        "  def __init__(self, D, M):\n",
        "    W = np.random.randn(D, M) / np.sqrt(D)\n",
        "    b = np.zeros(M)\n",
        "    \n",
        "    self.W = tf.Variable(W.astype(np.float32))\n",
        "    self.b = tf.Variable(b.astype(np.float32))\n",
        "    \n",
        "    self.params = [self.W, self.b]\n",
        "  \n",
        "  def forward(self, X):\n",
        "    return tf.nn.relu(tf.matmul(X, self.W)+self.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptU_nAxpEe7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FinalLayer():\n",
        "  def __init__(self, M, K):\n",
        "    W = np.random.randn(M, K) / np.sqrt(M)\n",
        "    b = np.zeros(K)\n",
        "    \n",
        "    self.W = tf.Variable(W.astype(np.float32))\n",
        "    self.b = tf.Variable(b.astype(np.float32))\n",
        "    \n",
        "    self.params = [self.W, self.b]\n",
        "    \n",
        "  def forward(self, Z):\n",
        "    return tf.matmul(Z, self.W)+self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAZEyjKpyPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN():\n",
        "  def __init__(self, filter_layer_sizes, hidden_layer_sizes):\n",
        "    self.filter_layer_sizes = filter_layer_sizes\n",
        "    self.hidden_layer_sizes = hidden_layer_sizes\n",
        "    \n",
        "  def set_session(self, session):\n",
        "    self.session = session\n",
        "    \n",
        "  def fit(self, X, Y, lr=1e-2, reg=0.01, training_epochs=5, batch_sz=30):\n",
        "    \n",
        "    lr = np.float32(lr)\n",
        "    reg = np.float32(reg)\n",
        "    \n",
        "    X, Y = shuffle(X, Y)\n",
        "    X = X.astype(np.float32)\n",
        "    Y = Y.astype(np.int32)\n",
        "    \n",
        "    Xtrain, Ytrain = X[:-1000], Y[:-1000]\n",
        "    Xtest, Ytest = X[-1000:], Y[-1000:]\n",
        "    \n",
        "    N = Xtrain.shape[0]\n",
        "    K = len(set(Ytrain))\n",
        "    \n",
        "    num_color_channels = Xtrain.shape[3]\n",
        "    image_w = Xtrain.shape[1]\n",
        "    image_h = Xtrain.shape[2]\n",
        "    \n",
        "    self.convpool_layers = []\n",
        "    for num_feature_maps, filter_width, filter_height in self.filter_layer_sizes:\n",
        "      c = convpool(num_feature_maps, num_color_channels, filter_width, filter_height)\n",
        "      self.convpool_layers.append(c)\n",
        "      num_color_channels = num_feature_maps\n",
        "      image_w = image_w // 2 \n",
        "      image_h = image_h // 2\n",
        "      \n",
        "    self.parameters = []\n",
        "    for obj in self.convpool_layers:\n",
        "      self.parameters += obj.params\n",
        "      \n",
        "    self.layers = []\n",
        "    M1 = num_feature_maps * image_w * image_h     # This is now 20 * 12 * 12 = 2880\n",
        "    for M2 in self.hidden_layer_sizes:\n",
        "      h = HiddenLayer(M1, M2)\n",
        "      self.layers.append(h)\n",
        "      M1 = M2\n",
        "      \n",
        "    f = FinalLayer(M1, K)\n",
        "    self.layers.append(f)\n",
        "    \n",
        "    for obj in self.layers:\n",
        "      self.parameters += obj.params\n",
        "      \n",
        "    X = tf.placeholder(tf.float32, shape=(None, 48, 48, 1), name='X')\n",
        "    Y = tf.placeholder(tf.int32, shape=(None,), name='Y')\n",
        "    \n",
        "    logits = self.tf_forward(X)\n",
        "    \n",
        "    rcost = reg*sum([tf.nn.l2_loss(p) for p in self.parameters])\n",
        "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y)) + rcost\n",
        "    \n",
        "    train_op = tf.train.MomentumOptimizer(lr, momentum=0.8, use_nesterov=True).minimize(cost)\n",
        "    \n",
        "    prediction = tf.argmax(logits, 1)\n",
        "    \n",
        "    self.session.run(tf.global_variables_initializer())\n",
        "    \n",
        "    n_batches = N // batch_sz\n",
        "    costs = []\n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "      Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\n",
        "      for j in range(n_batches):\n",
        "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "        Ybatch = Ytrain[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "        \n",
        "        self.session.run(train_op, feed_dict={X:Xbatch, Y:Ybatch})\n",
        "        \n",
        "        if j % 20 == 0:\n",
        "          c, p = self.session.run([cost, prediction], feed_dict={X:Xtest, Y:Ytest})\n",
        "          costs.append(c)\n",
        "          e = np.mean(p != Ytest)\n",
        "          print(\"Epoch\", (epoch + 1), \"Batch\", j, \": cost =\", \"%.2f\" % c, \"error rate =\", \"%.2f\" % e)\n",
        "  \n",
        "    plt.plot(costs, label='cost')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "  def tf_forward(self, X):\n",
        "    Z = X\n",
        "    for obj in self.convpool_layers:\n",
        "      Z = obj.convpool_forward(Z)\n",
        "    Z = tf.layers.flatten(Z)\n",
        "    for obj in self.layers:\n",
        "      Z = obj.forward(Z)\n",
        "    return Z   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7gXitQDo8Wt",
        "colab_type": "code",
        "outputId": "717301d5-3520-417f-969b-d19279a8e680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def main():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive', force_remount = True)\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  first = True\n",
        "  for line in open('/content/gdrive/My Drive/Colab Notebooks/Convolutional Neural Networks/fer2013.csv'):\n",
        "    if first:\n",
        "      first = False\n",
        "    else:\n",
        "      row = line.split(',')\n",
        "      Y.append(int(row[0])) # before int it is ['0', '0', '2', '4', '6', '2', '4'], after int it is [0, 0, 2, 4, 6, 2, 4]\n",
        "      X.append([int(p) for p in row[1].split()])\n",
        "\n",
        "  X, Y = np.array(X) / 255.0, np.array(Y)\n",
        "\n",
        "  # balance the 1 class\n",
        "  X0, Y0 = X[Y!=1, :], Y[Y!=1]\n",
        "  X1 = X[Y==1, :]\n",
        "  X1 = np.repeat(X1, 9, axis=0)\n",
        "  X = np.vstack([X0, X1])\n",
        "  Y = np.concatenate((Y0, [1]*len(X1)))\n",
        "\n",
        "  N,D = X.shape\n",
        "  d = int(np.sqrt(D))\n",
        "  X = X.reshape(N, d, d, 1)\n",
        "\n",
        "  model = CNN(\n",
        "  filter_layer_sizes = [(20, 5, 5), (20, 5, 5)],\n",
        "  hidden_layer_sizes = [500, 300],\n",
        "  )\n",
        "\n",
        "  session = tf.InteractiveSession()\n",
        "  model.set_session(session)\n",
        "  model.fit(X, Y)\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 : cost = 6.42 error rate = 0.76\n",
            "Epoch 1 Batch 20 : cost = 6.30 error rate = 0.76\n",
            "Epoch 1 Batch 40 : cost = 6.20 error rate = 0.76\n",
            "Epoch 1 Batch 60 : cost = 6.11 error rate = 0.76\n",
            "Epoch 1 Batch 80 : cost = 6.04 error rate = 0.76\n",
            "Epoch 1 Batch 100 : cost = 5.94 error rate = 0.76\n",
            "Epoch 1 Batch 120 : cost = 5.86 error rate = 0.76\n",
            "Epoch 1 Batch 140 : cost = 5.78 error rate = 0.76\n",
            "Epoch 1 Batch 160 : cost = 5.70 error rate = 0.76\n",
            "Epoch 1 Batch 180 : cost = 5.62 error rate = 0.76\n",
            "Epoch 1 Batch 200 : cost = 5.54 error rate = 0.76\n",
            "Epoch 1 Batch 220 : cost = 5.46 error rate = 0.76\n",
            "Epoch 1 Batch 240 : cost = 5.39 error rate = 0.77\n",
            "Epoch 1 Batch 260 : cost = 5.31 error rate = 0.75\n",
            "Epoch 1 Batch 280 : cost = 5.26 error rate = 0.80\n",
            "Epoch 1 Batch 300 : cost = 5.17 error rate = 0.75\n",
            "Epoch 1 Batch 320 : cost = 5.09 error rate = 0.74\n",
            "Epoch 1 Batch 340 : cost = 5.01 error rate = 0.71\n",
            "Epoch 1 Batch 360 : cost = 4.94 error rate = 0.73\n",
            "Epoch 1 Batch 380 : cost = 4.88 error rate = 0.74\n",
            "Epoch 1 Batch 400 : cost = 4.81 error rate = 0.71\n",
            "Epoch 1 Batch 420 : cost = 4.76 error rate = 0.70\n",
            "Epoch 1 Batch 440 : cost = 4.68 error rate = 0.70\n",
            "Epoch 1 Batch 460 : cost = 4.62 error rate = 0.71\n",
            "Epoch 1 Batch 480 : cost = 4.55 error rate = 0.67\n",
            "Epoch 1 Batch 500 : cost = 4.48 error rate = 0.66\n",
            "Epoch 1 Batch 520 : cost = 4.44 error rate = 0.69\n",
            "Epoch 1 Batch 540 : cost = 4.39 error rate = 0.68\n",
            "Epoch 1 Batch 560 : cost = 4.31 error rate = 0.65\n",
            "Epoch 1 Batch 580 : cost = 4.28 error rate = 0.65\n",
            "Epoch 1 Batch 600 : cost = 4.22 error rate = 0.66\n",
            "Epoch 1 Batch 620 : cost = 4.20 error rate = 0.68\n",
            "Epoch 1 Batch 640 : cost = 4.13 error rate = 0.67\n",
            "Epoch 1 Batch 660 : cost = 4.13 error rate = 0.69\n",
            "Epoch 1 Batch 680 : cost = 4.02 error rate = 0.65\n",
            "Epoch 1 Batch 700 : cost = 3.96 error rate = 0.64\n",
            "Epoch 1 Batch 720 : cost = 3.93 error rate = 0.63\n",
            "Epoch 1 Batch 740 : cost = 3.88 error rate = 0.65\n",
            "Epoch 1 Batch 760 : cost = 3.83 error rate = 0.64\n",
            "Epoch 1 Batch 780 : cost = 3.85 error rate = 0.67\n",
            "Epoch 1 Batch 800 : cost = 3.75 error rate = 0.63\n",
            "Epoch 1 Batch 820 : cost = 3.69 error rate = 0.61\n",
            "Epoch 1 Batch 840 : cost = 3.66 error rate = 0.61\n",
            "Epoch 1 Batch 860 : cost = 3.64 error rate = 0.62\n",
            "Epoch 1 Batch 880 : cost = 3.62 error rate = 0.65\n",
            "Epoch 1 Batch 900 : cost = 3.56 error rate = 0.63\n",
            "Epoch 1 Batch 920 : cost = 3.51 error rate = 0.62\n",
            "Epoch 1 Batch 940 : cost = 3.49 error rate = 0.62\n",
            "Epoch 1 Batch 960 : cost = 3.44 error rate = 0.62\n",
            "Epoch 1 Batch 980 : cost = 3.41 error rate = 0.62\n",
            "Epoch 1 Batch 1000 : cost = 3.41 error rate = 0.65\n",
            "Epoch 1 Batch 1020 : cost = 3.37 error rate = 0.65\n",
            "Epoch 1 Batch 1040 : cost = 3.29 error rate = 0.60\n",
            "Epoch 1 Batch 1060 : cost = 3.33 error rate = 0.64\n",
            "Epoch 1 Batch 1080 : cost = 3.24 error rate = 0.62\n",
            "Epoch 1 Batch 1100 : cost = 3.22 error rate = 0.64\n",
            "Epoch 1 Batch 1120 : cost = 3.16 error rate = 0.59\n",
            "Epoch 1 Batch 1140 : cost = 3.14 error rate = 0.60\n",
            "Epoch 1 Batch 1160 : cost = 3.11 error rate = 0.60\n",
            "Epoch 1 Batch 1180 : cost = 3.11 error rate = 0.61\n",
            "Epoch 1 Batch 1200 : cost = 3.05 error rate = 0.60\n",
            "Epoch 1 Batch 1220 : cost = 3.02 error rate = 0.59\n",
            "Epoch 1 Batch 1240 : cost = 3.03 error rate = 0.61\n",
            "Epoch 1 Batch 1260 : cost = 2.97 error rate = 0.59\n",
            "Epoch 1 Batch 1280 : cost = 2.97 error rate = 0.62\n",
            "Epoch 1 Batch 1300 : cost = 2.91 error rate = 0.58\n",
            "Epoch 2 Batch 0 : cost = 2.92 error rate = 0.61\n",
            "Epoch 2 Batch 20 : cost = 2.91 error rate = 0.61\n",
            "Epoch 2 Batch 40 : cost = 2.87 error rate = 0.59\n",
            "Epoch 2 Batch 60 : cost = 2.86 error rate = 0.60\n",
            "Epoch 2 Batch 80 : cost = 2.85 error rate = 0.60\n",
            "Epoch 2 Batch 100 : cost = 2.79 error rate = 0.60\n",
            "Epoch 2 Batch 120 : cost = 2.77 error rate = 0.58\n",
            "Epoch 2 Batch 140 : cost = 2.75 error rate = 0.58\n",
            "Epoch 2 Batch 160 : cost = 2.77 error rate = 0.62\n",
            "Epoch 2 Batch 180 : cost = 2.72 error rate = 0.59\n",
            "Epoch 2 Batch 200 : cost = 2.67 error rate = 0.57\n",
            "Epoch 2 Batch 220 : cost = 2.67 error rate = 0.59\n",
            "Epoch 2 Batch 240 : cost = 2.66 error rate = 0.58\n",
            "Epoch 2 Batch 260 : cost = 2.62 error rate = 0.58\n",
            "Epoch 2 Batch 280 : cost = 2.60 error rate = 0.58\n",
            "Epoch 2 Batch 300 : cost = 2.61 error rate = 0.59\n",
            "Epoch 2 Batch 320 : cost = 2.54 error rate = 0.56\n",
            "Epoch 2 Batch 340 : cost = 2.62 error rate = 0.61\n",
            "Epoch 2 Batch 360 : cost = 2.54 error rate = 0.57\n",
            "Epoch 2 Batch 380 : cost = 2.53 error rate = 0.60\n",
            "Epoch 2 Batch 400 : cost = 2.50 error rate = 0.57\n",
            "Epoch 2 Batch 420 : cost = 2.48 error rate = 0.56\n",
            "Epoch 2 Batch 440 : cost = 2.50 error rate = 0.59\n",
            "Epoch 2 Batch 460 : cost = 2.42 error rate = 0.54\n",
            "Epoch 2 Batch 480 : cost = 2.49 error rate = 0.59\n",
            "Epoch 2 Batch 500 : cost = 2.43 error rate = 0.58\n",
            "Epoch 2 Batch 520 : cost = 2.45 error rate = 0.58\n",
            "Epoch 2 Batch 540 : cost = 2.37 error rate = 0.55\n",
            "Epoch 2 Batch 560 : cost = 2.39 error rate = 0.58\n",
            "Epoch 2 Batch 580 : cost = 2.34 error rate = 0.56\n",
            "Epoch 2 Batch 600 : cost = 2.41 error rate = 0.59\n",
            "Epoch 2 Batch 620 : cost = 2.30 error rate = 0.54\n",
            "Epoch 2 Batch 640 : cost = 2.34 error rate = 0.58\n",
            "Epoch 2 Batch 660 : cost = 2.29 error rate = 0.56\n",
            "Epoch 2 Batch 680 : cost = 2.28 error rate = 0.56\n",
            "Epoch 2 Batch 700 : cost = 2.26 error rate = 0.55\n",
            "Epoch 2 Batch 720 : cost = 2.25 error rate = 0.56\n",
            "Epoch 2 Batch 740 : cost = 2.23 error rate = 0.55\n",
            "Epoch 2 Batch 760 : cost = 2.23 error rate = 0.56\n",
            "Epoch 2 Batch 780 : cost = 2.25 error rate = 0.59\n",
            "Epoch 2 Batch 800 : cost = 2.25 error rate = 0.57\n",
            "Epoch 2 Batch 820 : cost = 2.20 error rate = 0.54\n",
            "Epoch 2 Batch 840 : cost = 2.19 error rate = 0.56\n",
            "Epoch 2 Batch 860 : cost = 2.15 error rate = 0.56\n",
            "Epoch 2 Batch 880 : cost = 2.17 error rate = 0.56\n",
            "Epoch 2 Batch 900 : cost = 2.13 error rate = 0.56\n",
            "Epoch 2 Batch 920 : cost = 2.15 error rate = 0.55\n",
            "Epoch 2 Batch 940 : cost = 2.13 error rate = 0.55\n",
            "Epoch 2 Batch 960 : cost = 2.15 error rate = 0.57\n",
            "Epoch 2 Batch 980 : cost = 2.12 error rate = 0.55\n",
            "Epoch 2 Batch 1000 : cost = 2.09 error rate = 0.53\n",
            "Epoch 2 Batch 1020 : cost = 2.12 error rate = 0.56\n",
            "Epoch 2 Batch 1040 : cost = 2.11 error rate = 0.55\n",
            "Epoch 2 Batch 1060 : cost = 2.10 error rate = 0.55\n",
            "Epoch 2 Batch 1080 : cost = 2.04 error rate = 0.54\n",
            "Epoch 2 Batch 1100 : cost = 2.06 error rate = 0.54\n",
            "Epoch 2 Batch 1120 : cost = 2.04 error rate = 0.55\n",
            "Epoch 2 Batch 1140 : cost = 2.02 error rate = 0.54\n",
            "Epoch 2 Batch 1160 : cost = 2.04 error rate = 0.55\n",
            "Epoch 2 Batch 1180 : cost = 2.02 error rate = 0.55\n",
            "Epoch 2 Batch 1200 : cost = 1.99 error rate = 0.52\n",
            "Epoch 2 Batch 1220 : cost = 2.03 error rate = 0.55\n",
            "Epoch 2 Batch 1240 : cost = 2.00 error rate = 0.53\n",
            "Epoch 2 Batch 1260 : cost = 1.96 error rate = 0.52\n",
            "Epoch 2 Batch 1280 : cost = 1.99 error rate = 0.54\n",
            "Epoch 2 Batch 1300 : cost = 1.97 error rate = 0.53\n",
            "Epoch 3 Batch 0 : cost = 2.01 error rate = 0.56\n",
            "Epoch 3 Batch 20 : cost = 1.97 error rate = 0.52\n",
            "Epoch 3 Batch 40 : cost = 1.97 error rate = 0.53\n",
            "Epoch 3 Batch 60 : cost = 1.94 error rate = 0.53\n",
            "Epoch 3 Batch 80 : cost = 1.97 error rate = 0.55\n",
            "Epoch 3 Batch 100 : cost = 1.91 error rate = 0.51\n",
            "Epoch 3 Batch 120 : cost = 1.95 error rate = 0.55\n",
            "Epoch 3 Batch 140 : cost = 1.89 error rate = 0.51\n",
            "Epoch 3 Batch 160 : cost = 1.91 error rate = 0.52\n",
            "Epoch 3 Batch 180 : cost = 1.91 error rate = 0.54\n",
            "Epoch 3 Batch 200 : cost = 1.91 error rate = 0.54\n",
            "Epoch 3 Batch 220 : cost = 1.94 error rate = 0.55\n",
            "Epoch 3 Batch 240 : cost = 1.88 error rate = 0.52\n",
            "Epoch 3 Batch 260 : cost = 1.96 error rate = 0.56\n",
            "Epoch 3 Batch 280 : cost = 1.86 error rate = 0.51\n",
            "Epoch 3 Batch 300 : cost = 1.85 error rate = 0.51\n",
            "Epoch 3 Batch 320 : cost = 1.88 error rate = 0.54\n",
            "Epoch 3 Batch 340 : cost = 1.86 error rate = 0.52\n",
            "Epoch 3 Batch 360 : cost = 1.86 error rate = 0.52\n",
            "Epoch 3 Batch 380 : cost = 1.87 error rate = 0.53\n",
            "Epoch 3 Batch 400 : cost = 1.85 error rate = 0.53\n",
            "Epoch 3 Batch 420 : cost = 1.87 error rate = 0.53\n",
            "Epoch 3 Batch 440 : cost = 1.86 error rate = 0.54\n",
            "Epoch 3 Batch 460 : cost = 1.87 error rate = 0.54\n",
            "Epoch 3 Batch 480 : cost = 1.88 error rate = 0.55\n",
            "Epoch 3 Batch 500 : cost = 1.82 error rate = 0.51\n",
            "Epoch 3 Batch 520 : cost = 1.79 error rate = 0.50\n",
            "Epoch 3 Batch 540 : cost = 1.79 error rate = 0.50\n",
            "Epoch 3 Batch 560 : cost = 1.86 error rate = 0.54\n",
            "Epoch 3 Batch 580 : cost = 1.80 error rate = 0.51\n",
            "Epoch 3 Batch 600 : cost = 1.77 error rate = 0.51\n",
            "Epoch 3 Batch 620 : cost = 1.78 error rate = 0.52\n",
            "Epoch 3 Batch 640 : cost = 1.81 error rate = 0.53\n",
            "Epoch 3 Batch 660 : cost = 1.75 error rate = 0.52\n",
            "Epoch 3 Batch 680 : cost = 1.74 error rate = 0.51\n",
            "Epoch 3 Batch 700 : cost = 1.77 error rate = 0.51\n",
            "Epoch 3 Batch 720 : cost = 1.78 error rate = 0.52\n",
            "Epoch 3 Batch 740 : cost = 1.78 error rate = 0.53\n",
            "Epoch 3 Batch 760 : cost = 1.85 error rate = 0.57\n",
            "Epoch 3 Batch 780 : cost = 1.76 error rate = 0.51\n",
            "Epoch 3 Batch 800 : cost = 1.73 error rate = 0.49\n",
            "Epoch 3 Batch 820 : cost = 1.72 error rate = 0.49\n",
            "Epoch 3 Batch 840 : cost = 1.73 error rate = 0.50\n",
            "Epoch 3 Batch 860 : cost = 1.76 error rate = 0.52\n",
            "Epoch 3 Batch 880 : cost = 1.77 error rate = 0.52\n",
            "Epoch 3 Batch 900 : cost = 1.75 error rate = 0.52\n",
            "Epoch 3 Batch 920 : cost = 1.74 error rate = 0.51\n",
            "Epoch 3 Batch 940 : cost = 1.73 error rate = 0.51\n",
            "Epoch 3 Batch 960 : cost = 1.71 error rate = 0.49\n",
            "Epoch 3 Batch 980 : cost = 1.74 error rate = 0.50\n",
            "Epoch 3 Batch 1000 : cost = 1.72 error rate = 0.50\n",
            "Epoch 3 Batch 1020 : cost = 1.75 error rate = 0.51\n",
            "Epoch 3 Batch 1040 : cost = 1.73 error rate = 0.51\n",
            "Epoch 3 Batch 1060 : cost = 1.70 error rate = 0.51\n",
            "Epoch 3 Batch 1080 : cost = 1.69 error rate = 0.50\n",
            "Epoch 3 Batch 1100 : cost = 1.69 error rate = 0.50\n",
            "Epoch 3 Batch 1120 : cost = 1.69 error rate = 0.49\n",
            "Epoch 3 Batch 1140 : cost = 1.73 error rate = 0.51\n",
            "Epoch 3 Batch 1160 : cost = 1.71 error rate = 0.51\n",
            "Epoch 3 Batch 1180 : cost = 1.67 error rate = 0.50\n",
            "Epoch 3 Batch 1200 : cost = 1.76 error rate = 0.52\n",
            "Epoch 3 Batch 1220 : cost = 1.74 error rate = 0.51\n",
            "Epoch 3 Batch 1240 : cost = 1.67 error rate = 0.49\n",
            "Epoch 3 Batch 1260 : cost = 1.69 error rate = 0.51\n",
            "Epoch 3 Batch 1280 : cost = 1.66 error rate = 0.48\n",
            "Epoch 3 Batch 1300 : cost = 1.68 error rate = 0.49\n",
            "Epoch 4 Batch 0 : cost = 1.68 error rate = 0.51\n",
            "Epoch 4 Batch 20 : cost = 1.70 error rate = 0.52\n",
            "Epoch 4 Batch 40 : cost = 1.69 error rate = 0.52\n",
            "Epoch 4 Batch 60 : cost = 1.68 error rate = 0.51\n",
            "Epoch 4 Batch 80 : cost = 1.71 error rate = 0.51\n",
            "Epoch 4 Batch 100 : cost = 1.65 error rate = 0.50\n",
            "Epoch 4 Batch 120 : cost = 1.71 error rate = 0.51\n",
            "Epoch 4 Batch 140 : cost = 1.66 error rate = 0.50\n",
            "Epoch 4 Batch 160 : cost = 1.67 error rate = 0.49\n",
            "Epoch 4 Batch 180 : cost = 1.66 error rate = 0.48\n",
            "Epoch 4 Batch 200 : cost = 1.71 error rate = 0.52\n",
            "Epoch 4 Batch 220 : cost = 1.65 error rate = 0.48\n",
            "Epoch 4 Batch 240 : cost = 1.68 error rate = 0.50\n",
            "Epoch 4 Batch 260 : cost = 1.65 error rate = 0.50\n",
            "Epoch 4 Batch 280 : cost = 1.65 error rate = 0.49\n",
            "Epoch 4 Batch 300 : cost = 1.64 error rate = 0.48\n",
            "Epoch 4 Batch 320 : cost = 1.64 error rate = 0.49\n",
            "Epoch 4 Batch 340 : cost = 1.65 error rate = 0.49\n",
            "Epoch 4 Batch 360 : cost = 1.63 error rate = 0.48\n",
            "Epoch 4 Batch 380 : cost = 1.66 error rate = 0.49\n",
            "Epoch 4 Batch 400 : cost = 1.69 error rate = 0.52\n",
            "Epoch 4 Batch 420 : cost = 1.70 error rate = 0.52\n",
            "Epoch 4 Batch 440 : cost = 1.68 error rate = 0.51\n",
            "Epoch 4 Batch 460 : cost = 1.63 error rate = 0.48\n",
            "Epoch 4 Batch 480 : cost = 1.62 error rate = 0.48\n",
            "Epoch 4 Batch 500 : cost = 1.63 error rate = 0.48\n",
            "Epoch 4 Batch 520 : cost = 1.65 error rate = 0.49\n",
            "Epoch 4 Batch 540 : cost = 1.59 error rate = 0.47\n",
            "Epoch 4 Batch 560 : cost = 1.63 error rate = 0.48\n",
            "Epoch 4 Batch 580 : cost = 1.71 error rate = 0.52\n",
            "Epoch 4 Batch 600 : cost = 1.65 error rate = 0.50\n",
            "Epoch 4 Batch 620 : cost = 1.62 error rate = 0.47\n",
            "Epoch 4 Batch 640 : cost = 1.63 error rate = 0.48\n",
            "Epoch 4 Batch 660 : cost = 1.61 error rate = 0.46\n",
            "Epoch 4 Batch 680 : cost = 1.61 error rate = 0.47\n",
            "Epoch 4 Batch 700 : cost = 1.63 error rate = 0.48\n",
            "Epoch 4 Batch 720 : cost = 1.62 error rate = 0.47\n",
            "Epoch 4 Batch 740 : cost = 1.67 error rate = 0.50\n",
            "Epoch 4 Batch 760 : cost = 1.65 error rate = 0.49\n",
            "Epoch 4 Batch 780 : cost = 1.66 error rate = 0.50\n",
            "Epoch 4 Batch 800 : cost = 1.63 error rate = 0.49\n",
            "Epoch 4 Batch 820 : cost = 1.59 error rate = 0.49\n",
            "Epoch 4 Batch 840 : cost = 1.60 error rate = 0.48\n",
            "Epoch 4 Batch 860 : cost = 1.63 error rate = 0.48\n",
            "Epoch 4 Batch 880 : cost = 1.66 error rate = 0.51\n",
            "Epoch 4 Batch 900 : cost = 1.62 error rate = 0.48\n",
            "Epoch 4 Batch 920 : cost = 1.60 error rate = 0.49\n",
            "Epoch 4 Batch 940 : cost = 1.61 error rate = 0.47\n",
            "Epoch 4 Batch 960 : cost = 1.63 error rate = 0.51\n",
            "Epoch 4 Batch 980 : cost = 1.62 error rate = 0.49\n",
            "Epoch 4 Batch 1000 : cost = 1.62 error rate = 0.48\n",
            "Epoch 4 Batch 1020 : cost = 1.62 error rate = 0.48\n",
            "Epoch 4 Batch 1040 : cost = 1.60 error rate = 0.49\n",
            "Epoch 4 Batch 1060 : cost = 1.57 error rate = 0.46\n",
            "Epoch 4 Batch 1080 : cost = 1.58 error rate = 0.47\n",
            "Epoch 4 Batch 1100 : cost = 1.65 error rate = 0.52\n",
            "Epoch 4 Batch 1120 : cost = 1.58 error rate = 0.47\n",
            "Epoch 4 Batch 1140 : cost = 1.59 error rate = 0.48\n",
            "Epoch 4 Batch 1160 : cost = 1.62 error rate = 0.49\n",
            "Epoch 4 Batch 1180 : cost = 1.61 error rate = 0.48\n",
            "Epoch 4 Batch 1200 : cost = 1.62 error rate = 0.49\n",
            "Epoch 4 Batch 1220 : cost = 1.60 error rate = 0.48\n",
            "Epoch 4 Batch 1240 : cost = 1.63 error rate = 0.51\n",
            "Epoch 4 Batch 1260 : cost = 1.62 error rate = 0.50\n",
            "Epoch 4 Batch 1280 : cost = 1.61 error rate = 0.48\n",
            "Epoch 4 Batch 1300 : cost = 1.59 error rate = 0.47\n",
            "Epoch 5 Batch 0 : cost = 1.59 error rate = 0.47\n",
            "Epoch 5 Batch 20 : cost = 1.62 error rate = 0.48\n",
            "Epoch 5 Batch 40 : cost = 1.60 error rate = 0.49\n",
            "Epoch 5 Batch 60 : cost = 1.60 error rate = 0.49\n",
            "Epoch 5 Batch 80 : cost = 1.58 error rate = 0.48\n",
            "Epoch 5 Batch 100 : cost = 1.61 error rate = 0.49\n",
            "Epoch 5 Batch 120 : cost = 1.59 error rate = 0.49\n",
            "Epoch 5 Batch 140 : cost = 1.58 error rate = 0.48\n",
            "Epoch 5 Batch 160 : cost = 1.58 error rate = 0.47\n",
            "Epoch 5 Batch 180 : cost = 1.61 error rate = 0.48\n",
            "Epoch 5 Batch 200 : cost = 1.60 error rate = 0.48\n",
            "Epoch 5 Batch 220 : cost = 1.60 error rate = 0.49\n",
            "Epoch 5 Batch 240 : cost = 1.59 error rate = 0.48\n",
            "Epoch 5 Batch 260 : cost = 1.61 error rate = 0.47\n",
            "Epoch 5 Batch 280 : cost = 1.57 error rate = 0.45\n",
            "Epoch 5 Batch 300 : cost = 1.62 error rate = 0.49\n",
            "Epoch 5 Batch 320 : cost = 1.59 error rate = 0.48\n",
            "Epoch 5 Batch 340 : cost = 1.58 error rate = 0.46\n",
            "Epoch 5 Batch 360 : cost = 1.57 error rate = 0.45\n",
            "Epoch 5 Batch 380 : cost = 1.62 error rate = 0.50\n",
            "Epoch 5 Batch 400 : cost = 1.60 error rate = 0.48\n",
            "Epoch 5 Batch 420 : cost = 1.66 error rate = 0.51\n",
            "Epoch 5 Batch 440 : cost = 1.59 error rate = 0.48\n",
            "Epoch 5 Batch 460 : cost = 1.59 error rate = 0.49\n",
            "Epoch 5 Batch 480 : cost = 1.63 error rate = 0.49\n",
            "Epoch 5 Batch 500 : cost = 1.59 error rate = 0.48\n",
            "Epoch 5 Batch 520 : cost = 1.65 error rate = 0.51\n",
            "Epoch 5 Batch 540 : cost = 1.56 error rate = 0.45\n",
            "Epoch 5 Batch 560 : cost = 1.60 error rate = 0.48\n",
            "Epoch 5 Batch 580 : cost = 1.59 error rate = 0.48\n",
            "Epoch 5 Batch 600 : cost = 1.57 error rate = 0.46\n",
            "Epoch 5 Batch 620 : cost = 1.57 error rate = 0.47\n",
            "Epoch 5 Batch 640 : cost = 1.59 error rate = 0.47\n",
            "Epoch 5 Batch 660 : cost = 1.57 error rate = 0.46\n",
            "Epoch 5 Batch 680 : cost = 1.60 error rate = 0.47\n",
            "Epoch 5 Batch 700 : cost = 1.59 error rate = 0.48\n",
            "Epoch 5 Batch 720 : cost = 1.57 error rate = 0.47\n",
            "Epoch 5 Batch 740 : cost = 1.66 error rate = 0.51\n",
            "Epoch 5 Batch 760 : cost = 1.63 error rate = 0.50\n",
            "Epoch 5 Batch 780 : cost = 1.58 error rate = 0.47\n",
            "Epoch 5 Batch 800 : cost = 1.56 error rate = 0.46\n",
            "Epoch 5 Batch 820 : cost = 1.61 error rate = 0.47\n",
            "Epoch 5 Batch 840 : cost = 1.58 error rate = 0.46\n",
            "Epoch 5 Batch 860 : cost = 1.60 error rate = 0.48\n",
            "Epoch 5 Batch 880 : cost = 1.58 error rate = 0.45\n",
            "Epoch 5 Batch 900 : cost = 1.57 error rate = 0.47\n",
            "Epoch 5 Batch 920 : cost = 1.58 error rate = 0.46\n",
            "Epoch 5 Batch 940 : cost = 1.59 error rate = 0.47\n",
            "Epoch 5 Batch 960 : cost = 1.58 error rate = 0.47\n",
            "Epoch 5 Batch 980 : cost = 1.56 error rate = 0.46\n",
            "Epoch 5 Batch 1000 : cost = 1.63 error rate = 0.49\n",
            "Epoch 5 Batch 1020 : cost = 1.56 error rate = 0.46\n",
            "Epoch 5 Batch 1040 : cost = 1.56 error rate = 0.45\n",
            "Epoch 5 Batch 1060 : cost = 1.57 error rate = 0.45\n",
            "Epoch 5 Batch 1080 : cost = 1.57 error rate = 0.46\n",
            "Epoch 5 Batch 1100 : cost = 1.60 error rate = 0.48\n",
            "Epoch 5 Batch 1120 : cost = 1.57 error rate = 0.46\n",
            "Epoch 5 Batch 1140 : cost = 1.58 error rate = 0.46\n",
            "Epoch 5 Batch 1160 : cost = 1.61 error rate = 0.49\n",
            "Epoch 5 Batch 1180 : cost = 1.61 error rate = 0.49\n",
            "Epoch 5 Batch 1200 : cost = 1.55 error rate = 0.46\n",
            "Epoch 5 Batch 1220 : cost = 1.56 error rate = 0.47\n",
            "Epoch 5 Batch 1240 : cost = 1.56 error rate = 0.46\n",
            "Epoch 5 Batch 1260 : cost = 1.56 error rate = 0.45\n",
            "Epoch 5 Batch 1280 : cost = 1.59 error rate = 0.47\n",
            "Epoch 5 Batch 1300 : cost = 1.58 error rate = 0.47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEiIUXGLiIQYFbeISIj5/4s2d9iXeh97AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}