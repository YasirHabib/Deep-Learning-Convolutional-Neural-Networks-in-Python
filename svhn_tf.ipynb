{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svhn_tf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasirHabib/Deep-Learning-Convolutional-Neural-Networks-in-Python/blob/master/svhn_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue91ElU3C55r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Fdkm0TJln7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djE5h-flKW4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_filter(shape):\n",
        "  w = np.random.randn(*shape) * np.sqrt(2.0 / np.prod(shape[:-1]))\n",
        "  return w.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA0cHZBlY_3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convpool(X, W, b):\n",
        "  # just assume pool size is (2,2) because we need to augment it with 1s\n",
        "  conv_out = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "  conv_out = tf.nn.bias_add(conv_out, b)\n",
        "  pool_out = tf.nn.max_pool(conv_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "  return tf.nn.relu(pool_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH-Dee76RHoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HiddenLayer():\n",
        "  def __init__(self, D, M):\n",
        "    W = np.random.randn(D, M) / np.sqrt(D)\n",
        "    b = np.zeros(M)\n",
        "    \n",
        "    self.W = tf.Variable(W.astype(np.float32))\n",
        "    self.b = tf.Variable(b.astype(np.float32))\n",
        "    \n",
        "    self.params = [self.W, self.b]\n",
        "    \n",
        "  def HiddenLayer_forward(self, X):\n",
        "    return tf.nn.relu(tf.matmul(X, self.W)+self.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox5Ya0d4Spza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FinalLayer():\n",
        "  def __init__(self, M, K):\n",
        "    W = np.random.randn(M, K) / np.sqrt(M)\n",
        "    b = np.zeros(K)\n",
        "    \n",
        "    self.W = tf.Variable(W.astype(np.float32))\n",
        "    self.b = tf.Variable(b.astype(np.float32))\n",
        "    \n",
        "    self.params = [self.W, self.b]\n",
        "    \n",
        "  def FinalLayer_forward(self, Z):\n",
        "    return tf.matmul(Z, self.W)+self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnFsaNP7IdgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN():\n",
        "  def __init__(self, size):\n",
        "    self.size = size\n",
        "    \n",
        "  def set_session(self, session):\n",
        "    self.session = session\n",
        "    \n",
        "  def fit(self, Xtrain, Ytrain, Xtest, Ytest, lr=1e-2, reg=0.01, training_epochs=10, batch_sz=500):\n",
        "    N = Xtrain.shape[0]\n",
        "    K = len(set(Ytrain))\n",
        "    \n",
        "    W1_shape = (5, 5, 3, 20) # (filter_width, filter_height, num_color_channels, num_feature_maps)\n",
        "    W1 = init_filter(W1_shape)\n",
        "    b1 = np.zeros(W1_shape[-1], dtype = np.float32)\n",
        "    \n",
        "    W2_shape = (5, 5, 20, 50) # (filter_width, filter_height, old_num_feature_maps, num_feature_maps)\n",
        "    W2 = init_filter(W2_shape)\n",
        "    b2 = np.zeros(W2_shape[-1], dtype = np.float32)\n",
        "    \n",
        "    X = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='X')\n",
        "    Y = tf.placeholder(tf.int32, shape=(None,), name='Y')\n",
        "    W1 = tf.Variable(W1)\n",
        "    b1 = tf.Variable(b1)\n",
        "    W2 = tf.Variable(W2)\n",
        "    b2 = tf.Variable(b2)\n",
        "    \n",
        "    self.parameters = [W1,b1,W2,b2]\n",
        "    \n",
        "    self.layers = []\n",
        "    h = HiddenLayer(W2_shape[-1]*8*8, self.size)\n",
        "    self.layers.append(h)\n",
        "    \n",
        "    f = FinalLayer(self.size, K)\n",
        "    self.layers.append(f)\n",
        "    \n",
        "    for obj in self.layers:\n",
        "      self.parameters += obj.params\n",
        "      \n",
        "    # forward pass\n",
        "    Z1 = convpool(X, W1, b1)\n",
        "    Z2 = convpool(Z1, W2, b2)\n",
        "    Z3 = tf.layers.flatten(Z2)\n",
        "    logits = self.tf_forward(Z3)\n",
        "    \n",
        "    rcost = reg*sum([tf.nn.l2_loss(p) for p in self.parameters])\n",
        "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y)) + rcost\n",
        "    \n",
        "    train_op = tf.train.MomentumOptimizer(lr, momentum=0.9, use_nesterov=True).minimize(cost)\n",
        "    \n",
        "    prediction = tf.argmax(logits, 1)\n",
        "    \n",
        "    self.session.run(tf.global_variables_initializer())\n",
        "    \n",
        "    n_batches = N // batch_sz\n",
        "    costs = []\n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "      for j in range(n_batches):\n",
        "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "        Ybatch = Ytrain[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "        \n",
        "        self.session.run(train_op, feed_dict={X:Xbatch, Y:Ybatch})\n",
        "        \n",
        "        if j % 20 == 0:\n",
        "          c, p = self.session.run([cost, prediction], feed_dict={X:Xtest, Y:Ytest})\n",
        "          costs.append(c)\n",
        "          e = np.mean(p != Ytest)\n",
        "          print(\"Epoch\", (epoch + 1), \"Batch\", j, \": cost =\", \"%.2f\" % c, \"error rate =\", \"%.2f\" % e)\n",
        "  \n",
        "    plt.plot(costs, label='cost')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "  def tf_forward(self, X):\n",
        "    for obj in self.layers[:-1]:\n",
        "      Z = obj.HiddenLayer_forward(X)\n",
        "    for obj in self.layers[-1:]:\n",
        "      logits = obj.FinalLayer_forward(Z)\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsUSEwI_CmnQ",
        "colab_type": "code",
        "outputId": "a8381e99-8bde-404f-f567-8fbef250da56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def main():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive', force_remount = True)\n",
        "  \n",
        "  train = scipy.io.loadmat('/content/gdrive/My Drive/Colab Notebooks/Convolutional Neural Networks/train_32x32.mat')\n",
        "  test = scipy.io.loadmat('/content/gdrive/My Drive/Colab Notebooks/Convolutional Neural Networks/test_32x32.mat')\n",
        "  \n",
        "  Xtrain = train['X']\n",
        "  Ytrain = train['y']\n",
        "  #print(Xtrain.shape)           (32, 32, 3, 73257)\n",
        "  #print(Ytrain.shape)           (73257, 1)\n",
        "  Ytrain = Ytrain.flatten() - 1\n",
        "  \n",
        "  Xtest = test['X']\n",
        "  Ytest = test['y']\n",
        "  #print(Xtest.shape)            (32, 32, 3, 26032)\n",
        "  #print(Ytest.shape)            (26032, 1)\n",
        "  Ytest = Ytest.flatten() - 1\n",
        "  \n",
        "  Xtrain = (Xtrain.transpose(3,0,1,2) / 255).astype(np.float32)\n",
        "  Xtest = (Xtest.transpose(3,0,1,2) / 255).astype(np.float32)\n",
        "  \n",
        "  model = CNN(500)\n",
        "  session = tf.InteractiveSession()\n",
        "  model.set_session(session)\n",
        "  model.fit(Xtrain, Ytrain, Xtest, Ytest)\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 13:24:40.248154 139895304906624 deprecation.py:323] From <ipython-input-7-7bbc670b3af3>:42: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 : cost = 5.52 error rate = 0.80\n",
            "Epoch 1 Batch 20 : cost = 5.39 error rate = 0.80\n",
            "Epoch 1 Batch 40 : cost = 5.25 error rate = 0.77\n",
            "Epoch 1 Batch 60 : cost = 5.10 error rate = 0.78\n",
            "Epoch 1 Batch 80 : cost = 4.95 error rate = 0.77\n",
            "Epoch 1 Batch 100 : cost = 4.78 error rate = 0.70\n",
            "Epoch 1 Batch 120 : cost = 4.65 error rate = 0.70\n",
            "Epoch 1 Batch 140 : cost = 4.28 error rate = 0.53\n",
            "Epoch 2 Batch 0 : cost = 4.16 error rate = 0.52\n",
            "Epoch 2 Batch 20 : cost = 3.87 error rate = 0.45\n",
            "Epoch 2 Batch 40 : cost = 3.55 error rate = 0.35\n",
            "Epoch 2 Batch 60 : cost = 3.31 error rate = 0.28\n",
            "Epoch 2 Batch 80 : cost = 3.11 error rate = 0.25\n",
            "Epoch 2 Batch 100 : cost = 3.08 error rate = 0.28\n",
            "Epoch 2 Batch 120 : cost = 2.88 error rate = 0.22\n",
            "Epoch 2 Batch 140 : cost = 2.74 error rate = 0.18\n",
            "Epoch 3 Batch 0 : cost = 2.77 error rate = 0.22\n",
            "Epoch 3 Batch 20 : cost = 2.62 error rate = 0.18\n",
            "Epoch 3 Batch 40 : cost = 2.62 error rate = 0.21\n",
            "Epoch 3 Batch 60 : cost = 2.49 error rate = 0.17\n",
            "Epoch 3 Batch 80 : cost = 2.40 error rate = 0.17\n",
            "Epoch 3 Batch 100 : cost = 2.35 error rate = 0.18\n",
            "Epoch 3 Batch 120 : cost = 2.26 error rate = 0.16\n",
            "Epoch 3 Batch 140 : cost = 2.20 error rate = 0.16\n",
            "Epoch 4 Batch 0 : cost = 2.22 error rate = 0.17\n",
            "Epoch 4 Batch 20 : cost = 2.13 error rate = 0.16\n",
            "Epoch 4 Batch 40 : cost = 2.08 error rate = 0.16\n",
            "Epoch 4 Batch 60 : cost = 2.05 error rate = 0.16\n",
            "Epoch 4 Batch 80 : cost = 1.98 error rate = 0.15\n",
            "Epoch 4 Batch 100 : cost = 1.95 error rate = 0.16\n",
            "Epoch 4 Batch 120 : cost = 1.88 error rate = 0.15\n",
            "Epoch 4 Batch 140 : cost = 1.83 error rate = 0.15\n",
            "Epoch 5 Batch 0 : cost = 1.85 error rate = 0.15\n",
            "Epoch 5 Batch 20 : cost = 1.79 error rate = 0.15\n",
            "Epoch 5 Batch 40 : cost = 1.74 error rate = 0.15\n",
            "Epoch 5 Batch 60 : cost = 1.73 error rate = 0.15\n",
            "Epoch 5 Batch 80 : cost = 1.68 error rate = 0.15\n",
            "Epoch 5 Batch 100 : cost = 1.66 error rate = 0.16\n",
            "Epoch 5 Batch 120 : cost = 1.60 error rate = 0.14\n",
            "Epoch 5 Batch 140 : cost = 1.57 error rate = 0.14\n",
            "Epoch 6 Batch 0 : cost = 1.59 error rate = 0.15\n",
            "Epoch 6 Batch 20 : cost = 1.53 error rate = 0.14\n",
            "Epoch 6 Batch 40 : cost = 1.50 error rate = 0.14\n",
            "Epoch 6 Batch 60 : cost = 1.49 error rate = 0.14\n",
            "Epoch 6 Batch 80 : cost = 1.46 error rate = 0.15\n",
            "Epoch 6 Batch 100 : cost = 1.44 error rate = 0.15\n",
            "Epoch 6 Batch 120 : cost = 1.39 error rate = 0.14\n",
            "Epoch 6 Batch 140 : cost = 1.37 error rate = 0.14\n",
            "Epoch 7 Batch 0 : cost = 1.40 error rate = 0.15\n",
            "Epoch 7 Batch 20 : cost = 1.34 error rate = 0.14\n",
            "Epoch 7 Batch 40 : cost = 1.32 error rate = 0.14\n",
            "Epoch 7 Batch 60 : cost = 1.32 error rate = 0.14\n",
            "Epoch 7 Batch 80 : cost = 1.29 error rate = 0.14\n",
            "Epoch 7 Batch 100 : cost = 1.28 error rate = 0.15\n",
            "Epoch 7 Batch 120 : cost = 1.24 error rate = 0.14\n",
            "Epoch 7 Batch 140 : cost = 1.22 error rate = 0.14\n",
            "Epoch 8 Batch 0 : cost = 1.26 error rate = 0.15\n",
            "Epoch 8 Batch 20 : cost = 1.20 error rate = 0.14\n",
            "Epoch 8 Batch 40 : cost = 1.18 error rate = 0.13\n",
            "Epoch 8 Batch 60 : cost = 1.20 error rate = 0.14\n",
            "Epoch 8 Batch 80 : cost = 1.17 error rate = 0.14\n",
            "Epoch 8 Batch 100 : cost = 1.17 error rate = 0.15\n",
            "Epoch 8 Batch 120 : cost = 1.13 error rate = 0.13\n",
            "Epoch 8 Batch 140 : cost = 1.12 error rate = 0.14\n",
            "Epoch 9 Batch 0 : cost = 1.15 error rate = 0.14\n",
            "Epoch 9 Batch 20 : cost = 1.10 error rate = 0.14\n",
            "Epoch 9 Batch 40 : cost = 1.09 error rate = 0.13\n",
            "Epoch 9 Batch 60 : cost = 1.10 error rate = 0.14\n",
            "Epoch 9 Batch 80 : cost = 1.08 error rate = 0.14\n",
            "Epoch 9 Batch 100 : cost = 1.08 error rate = 0.15\n",
            "Epoch 9 Batch 120 : cost = 1.04 error rate = 0.13\n",
            "Epoch 9 Batch 140 : cost = 1.03 error rate = 0.13\n",
            "Epoch 10 Batch 0 : cost = 1.07 error rate = 0.14\n",
            "Epoch 10 Batch 20 : cost = 1.02 error rate = 0.13\n",
            "Epoch 10 Batch 40 : cost = 1.01 error rate = 0.13\n",
            "Epoch 10 Batch 60 : cost = 1.03 error rate = 0.14\n",
            "Epoch 10 Batch 80 : cost = 1.01 error rate = 0.14\n",
            "Epoch 10 Batch 100 : cost = 1.02 error rate = 0.15\n",
            "Epoch 10 Batch 120 : cost = 0.98 error rate = 0.13\n",
            "Epoch 10 Batch 140 : cost = 0.97 error rate = 0.13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEmBU3CIiAUbFLSISYP4/6JtPA4lwFDYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}