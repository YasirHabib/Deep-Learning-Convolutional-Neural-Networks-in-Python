{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svhn_tf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasirHabib/Deep-Learning-Convolutional-Neural-Networks-in-Python/blob/master/svhn_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue91ElU3C55r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Fdkm0TJln7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djE5h-flKW4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_filter(shape):\n",
        "  w = np.random.randn(*shape) * np.sqrt(2.0 / np.prod(shape[:-1]))\n",
        "  return w.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA0cHZBlY_3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convpool(X, W, b):\n",
        "  # just assume pool size is (2,2) because we need to augment it with 1s\n",
        "  conv_out = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "  conv_out = tf.nn.bias_add(conv_out, b)\n",
        "  pool_out = tf.nn.max_pool(conv_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "  return tf.nn.relu(pool_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH-Dee76RHoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HiddenLayer():\n",
        "  def __init__(self, D, M):\n",
        "    W = np.random.randn(D, M) / np.sqrt(D)\n",
        "    b = np.zeros(M)\n",
        "    \n",
        "    self.W = tf.Variable(W.astype(np.float32))\n",
        "    self.b = tf.Variable(b.astype(np.float32))\n",
        "    \n",
        "    self.params = [self.W, self.b]\n",
        "    \n",
        "  def HiddenLayer_forward(self, X):\n",
        "    return tf.nn.relu(tf.matmul(X, self.W)+self.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox5Ya0d4Spza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FinalLayer():\n",
        "  def __init__(self, M, K):\n",
        "    W = np.random.randn(M, K) / np.sqrt(M)\n",
        "    b = np.zeros(K)\n",
        "    \n",
        "    self.W = tf.Variable(W.astype(np.float32))\n",
        "    self.b = tf.Variable(b.astype(np.float32))\n",
        "    \n",
        "    self.params = [self.W, self.b]\n",
        "    \n",
        "  def FinalLayer_forward(self, Z):\n",
        "    return tf.matmul(Z, self.W)+self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnFsaNP7IdgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ANN():\n",
        "  def __init__(self, size):\n",
        "    self.size = size\n",
        "    \n",
        "  def set_session(self, session):\n",
        "    self.session = session\n",
        "    \n",
        "  def fit(self, Xtrain, Ytrain, Xtest, Ytest, lr=1e-2, reg=0.01, training_epochs=10, batch_sz=500):\n",
        "    N = Xtrain.shape[0]\n",
        "    K = len(set(Ytrain))\n",
        "    \n",
        "    W1_shape = (5, 5, 3, 20) # (filter_width, filter_height, num_color_channels, num_feature_maps)\n",
        "    W1 = init_filter(W1_shape)\n",
        "    b1 = np.zeros(W1_shape[-1], dtype = np.float32)\n",
        "    \n",
        "    W2_shape = (5, 5, 20, 50) # (filter_width, filter_height, old_num_feature_maps, num_feature_maps)\n",
        "    W2 = init_filter(W2_shape)\n",
        "    b2 = np.zeros(W2_shape[-1], dtype = np.float32)\n",
        "    \n",
        "    X = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='X')\n",
        "    Y = tf.placeholder(tf.int32, shape=(None,), name='Y')\n",
        "    W1 = tf.Variable(W1)\n",
        "    b1 = tf.Variable(b1)\n",
        "    W2 = tf.Variable(W2)\n",
        "    b2 = tf.Variable(b2)\n",
        "    \n",
        "    self.parameters = [W1,b1,W2,b2]\n",
        "    \n",
        "    self.layers = []\n",
        "    h = HiddenLayer(W2_shape[-1]*8*8, self.size)\n",
        "    self.layers.append(h)\n",
        "    \n",
        "    f = FinalLayer(self.size, K)\n",
        "    self.layers.append(f)\n",
        "    \n",
        "    for obj in self.layers:\n",
        "      self.parameters += obj.params\n",
        "      \n",
        "    # forward pass\n",
        "    Z1 = convpool(X, W1, b1)\n",
        "    Z2 = convpool(Z1, W2, b2)\n",
        "    Z3 = tf.layers.flatten(Z2)\n",
        "    logits = self.tf_forward(Z3)\n",
        "    \n",
        "    rcost = reg*sum([tf.nn.l2_loss(p) for p in self.parameters])\n",
        "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y)) + rcost\n",
        "    \n",
        "    train_op = tf.train.MomentumOptimizer(lr, momentum=0.9, use_nesterov=True).minimize(cost)\n",
        "    \n",
        "    prediction = tf.argmax(logits, 1)\n",
        "    \n",
        "    self.session.run(tf.global_variables_initializer())\n",
        "    \n",
        "    n_batches = N // batch_sz\n",
        "    costs = []\n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "      for j in range(n_batches):\n",
        "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "        Ybatch = Ytrain[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "        \n",
        "        self.session.run(train_op, feed_dict={X:Xbatch, Y:Ybatch})\n",
        "        \n",
        "        if j % 20 == 0:\n",
        "          c, p = self.session.run([cost, prediction], feed_dict={X:Xtest, Y:Ytest})\n",
        "          costs.append(c)\n",
        "          e = np.mean(p != Ytest)\n",
        "          print(\"Epoch\", (epoch + 1), \"Batch\", j, \": cost =\", \"%.2f\" % c, \"error rate =\", \"%.2f\" % e)\n",
        "  \n",
        "    plt.plot(costs, label='cost')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "  def tf_forward(self, X):\n",
        "    for obj in self.layers[:-1]:\n",
        "      Z = obj.HiddenLayer_forward(X)\n",
        "    for obj in self.layers[-1:]:\n",
        "      logits = obj.FinalLayer_forward(Z)\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsUSEwI_CmnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d45e7596-0a12-46da-dc4d-78ae2920678d"
      },
      "source": [
        "def main():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive', force_remount = True)\n",
        "  \n",
        "  train = scipy.io.loadmat('/content/gdrive/My Drive/Colab Notebooks/Convolutional Neural Networks/train_32x32.mat')\n",
        "  test = scipy.io.loadmat('/content/gdrive/My Drive/Colab Notebooks/Convolutional Neural Networks/test_32x32.mat')\n",
        "  \n",
        "  Xtrain = train['X']\n",
        "  Ytrain = train['y']\n",
        "  #print(Xtrain.shape)           (32, 32, 3, 73257)\n",
        "  #print(Ytrain.shape)           (73257, 1)\n",
        "  Ytrain = Ytrain.flatten() - 1\n",
        "  \n",
        "  Xtest = test['X']\n",
        "  Ytest = test['y']\n",
        "  #print(Xtest.shape)            (32, 32, 3, 26032)\n",
        "  #print(Ytest.shape)            (26032, 1)\n",
        "  Ytest = Ytest.flatten() - 1\n",
        "  \n",
        "  Xtrain = (Xtrain.transpose(3,0,1,2) / 255).astype(np.float32)\n",
        "  Xtest = (Xtest.transpose(3,0,1,2) / 255).astype(np.float32)\n",
        "  \n",
        "  model = ANN(500)\n",
        "  session = tf.InteractiveSession()\n",
        "  model.set_session(session)\n",
        "  model.fit(Xtrain, Ytrain, Xtest, Ytest)\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 : cost = 5.49 error rate = 0.80\n",
            "Epoch 1 Batch 20 : cost = 5.37 error rate = 0.80\n",
            "Epoch 1 Batch 40 : cost = 5.23 error rate = 0.76\n",
            "Epoch 1 Batch 60 : cost = 5.07 error rate = 0.75\n",
            "Epoch 1 Batch 80 : cost = 4.90 error rate = 0.77\n",
            "Epoch 1 Batch 100 : cost = 4.68 error rate = 0.65\n",
            "Epoch 1 Batch 120 : cost = 4.68 error rate = 0.73\n",
            "Epoch 1 Batch 140 : cost = 4.37 error rate = 0.56\n",
            "Epoch 2 Batch 0 : cost = 4.01 error rate = 0.45\n",
            "Epoch 2 Batch 20 : cost = 3.71 error rate = 0.39\n",
            "Epoch 2 Batch 40 : cost = 3.62 error rate = 0.40\n",
            "Epoch 2 Batch 60 : cost = 3.27 error rate = 0.26\n",
            "Epoch 2 Batch 80 : cost = 3.10 error rate = 0.25\n",
            "Epoch 2 Batch 100 : cost = 3.00 error rate = 0.24\n",
            "Epoch 2 Batch 120 : cost = 3.06 error rate = 0.30\n",
            "Epoch 2 Batch 140 : cost = 2.77 error rate = 0.19\n",
            "Epoch 3 Batch 0 : cost = 2.74 error rate = 0.20\n",
            "Epoch 3 Batch 20 : cost = 2.65 error rate = 0.19\n",
            "Epoch 3 Batch 40 : cost = 2.65 error rate = 0.22\n",
            "Epoch 3 Batch 60 : cost = 2.51 error rate = 0.18\n",
            "Epoch 3 Batch 80 : cost = 2.43 error rate = 0.18\n",
            "Epoch 3 Batch 100 : cost = 2.36 error rate = 0.18\n",
            "Epoch 3 Batch 120 : cost = 2.30 error rate = 0.17\n",
            "Epoch 3 Batch 140 : cost = 2.22 error rate = 0.16\n",
            "Epoch 4 Batch 0 : cost = 2.21 error rate = 0.16\n",
            "Epoch 4 Batch 20 : cost = 2.15 error rate = 0.17\n",
            "Epoch 4 Batch 40 : cost = 2.09 error rate = 0.16\n",
            "Epoch 4 Batch 60 : cost = 2.06 error rate = 0.16\n",
            "Epoch 4 Batch 80 : cost = 2.00 error rate = 0.16\n",
            "Epoch 4 Batch 100 : cost = 1.95 error rate = 0.16\n",
            "Epoch 4 Batch 120 : cost = 1.90 error rate = 0.16\n",
            "Epoch 4 Batch 140 : cost = 1.85 error rate = 0.15\n",
            "Epoch 5 Batch 0 : cost = 1.84 error rate = 0.15\n",
            "Epoch 5 Batch 20 : cost = 1.80 error rate = 0.15\n",
            "Epoch 5 Batch 40 : cost = 1.75 error rate = 0.15\n",
            "Epoch 5 Batch 60 : cost = 1.74 error rate = 0.15\n",
            "Epoch 5 Batch 80 : cost = 1.69 error rate = 0.15\n",
            "Epoch 5 Batch 100 : cost = 1.66 error rate = 0.16\n",
            "Epoch 5 Batch 120 : cost = 1.62 error rate = 0.15\n",
            "Epoch 5 Batch 140 : cost = 1.58 error rate = 0.15\n",
            "Epoch 6 Batch 0 : cost = 1.58 error rate = 0.15\n",
            "Epoch 6 Batch 20 : cost = 1.54 error rate = 0.15\n",
            "Epoch 6 Batch 40 : cost = 1.50 error rate = 0.14\n",
            "Epoch 6 Batch 60 : cost = 1.50 error rate = 0.14\n",
            "Epoch 6 Batch 80 : cost = 1.46 error rate = 0.15\n",
            "Epoch 6 Batch 100 : cost = 1.44 error rate = 0.15\n",
            "Epoch 6 Batch 120 : cost = 1.41 error rate = 0.14\n",
            "Epoch 6 Batch 140 : cost = 1.38 error rate = 0.14\n",
            "Epoch 7 Batch 0 : cost = 1.39 error rate = 0.14\n",
            "Epoch 7 Batch 20 : cost = 1.35 error rate = 0.14\n",
            "Epoch 7 Batch 40 : cost = 1.32 error rate = 0.13\n",
            "Epoch 7 Batch 60 : cost = 1.33 error rate = 0.14\n",
            "Epoch 7 Batch 80 : cost = 1.30 error rate = 0.14\n",
            "Epoch 7 Batch 100 : cost = 1.28 error rate = 0.15\n",
            "Epoch 7 Batch 120 : cost = 1.25 error rate = 0.14\n",
            "Epoch 7 Batch 140 : cost = 1.23 error rate = 0.14\n",
            "Epoch 8 Batch 0 : cost = 1.24 error rate = 0.14\n",
            "Epoch 8 Batch 20 : cost = 1.21 error rate = 0.14\n",
            "Epoch 8 Batch 40 : cost = 1.19 error rate = 0.13\n",
            "Epoch 8 Batch 60 : cost = 1.20 error rate = 0.14\n",
            "Epoch 8 Batch 80 : cost = 1.17 error rate = 0.14\n",
            "Epoch 8 Batch 100 : cost = 1.16 error rate = 0.14\n",
            "Epoch 8 Batch 120 : cost = 1.14 error rate = 0.14\n",
            "Epoch 8 Batch 140 : cost = 1.12 error rate = 0.13\n",
            "Epoch 9 Batch 0 : cost = 1.13 error rate = 0.14\n",
            "Epoch 9 Batch 20 : cost = 1.11 error rate = 0.14\n",
            "Epoch 9 Batch 40 : cost = 1.09 error rate = 0.13\n",
            "Epoch 9 Batch 60 : cost = 1.11 error rate = 0.14\n",
            "Epoch 9 Batch 80 : cost = 1.08 error rate = 0.14\n",
            "Epoch 9 Batch 100 : cost = 1.07 error rate = 0.14\n",
            "Epoch 9 Batch 120 : cost = 1.05 error rate = 0.13\n",
            "Epoch 9 Batch 140 : cost = 1.04 error rate = 0.13\n",
            "Epoch 10 Batch 0 : cost = 1.05 error rate = 0.13\n",
            "Epoch 10 Batch 20 : cost = 1.03 error rate = 0.14\n",
            "Epoch 10 Batch 40 : cost = 1.01 error rate = 0.13\n",
            "Epoch 10 Batch 60 : cost = 1.03 error rate = 0.14\n",
            "Epoch 10 Batch 80 : cost = 1.01 error rate = 0.13\n",
            "Epoch 10 Batch 100 : cost = 1.01 error rate = 0.14\n",
            "Epoch 10 Batch 120 : cost = 0.99 error rate = 0.13\n",
            "Epoch 10 Batch 140 : cost = 0.97 error rate = 0.13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxS0iEmBU3CIiAeZ/AN5r2Z3LwPuQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}